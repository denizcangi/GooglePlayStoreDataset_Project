# -*- coding: utf-8 -*-
"""DataScience_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_N6Iu-s_ruKmGGw-wWOOCtnf1g408OgU

We are using Google Play Store apps dataset which is provided from Kaggle. Dataset consists of 10842 rows and 13 columns, each row represent an app from Google Play Store and each column represent a particular content of the app. Columns of the dataset are name of the app, category of the app, rating of the app, number of reviews of the app, size of the app, installation number of the app, type (free/paid) of the app, price of the app, content rating (everyone/adult/teenager) of the app, genres of the app, last update date of the app, current version of the app and android version of the app. 

According to the reports of Statcounter over the 2018 Android made up %74.45 of the of the smartphone sector, all apps for Android phones are housed in Google Play Store. This shows that, this dataset of Google Play Store apps and analysis of it will be enlightening for mobile application developers. Since there are many users, the mobile apps can be profitable for many developers, because of this many more apps are being developed for every need of the people. When a consumer is browsing an app for his/her needs, first thing he/she consider would be app’s rating. Ratings of the app is an important parameter that shows how better the app performs compared to the other apps for the same need of the consumer. If given a choice, most consumers would be more likely to download an app with between 4 to 5 rating, rather than an app with below 3 rating. As a consequence, an app’s download and rating are related to each other in the way that high rating leads to more download which results in more profit for the developers. 

Rating depends on various parameters, in this project we aimed predict the rating of the apps before they are put up on the Google Play Store with correlation or regression between ratings and categories, number of reviews, sizes and types (paid or free) of the apps, number of installations, content ratings and the date of their latest update on Google Play Store.

Methods that we have used are kNN Classifier, Linear Regression, Random Forest Regression, Decision Tree Regressor. We used these methods to calculate mean absolute errors, mean square errors, root mean squared errors. The mean absolute error is an average of the absolute errors. Mean squared error is the average squared difference between the estimated values and the actual value. Root mean square error (RMSE) is a way to measure the error of a model in predicting quantitative data. Our reason to calculate all of these errors, are to find out that which machine learning algorithm fit to our data best.
"""

from google.colab import drive
drive.mount('/content/drive')

"""First of all, we imported the packages we need to clean the data."""

import pandas as pd
import numpy as np
from datetime import datetime,date
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

"""Then we read our csv and converted it to dataframe."""

df=pd.read_csv('/content/drive/My Drive/googleplaystore.csv')
print(df.head())

"""To determine the types of the dataframe indexes, we printed dtypes of dataframe."""

print(df.dtypes)

"""To make column names more ordered we changed the name of columns which has " " to "_". """

df.columns = df.columns.str.replace(' ', '_')

"""Then for making data more briefly, we printed dataframe's shape."""

print("Shape of the data is", df.shape)

"""For determining the size of the applications, we converted megabytes to "e+6" and kilobytes to
"e+3".
"""

df.Size=df.Size.str.replace('k','e+3')
df.Size=df.Size.str.replace('M','e+6')

"""We created a new column which is named "Correctness" to determine the are the size of applications is float or not. Then we created a function which is  named "is_convertable", we passed every size to this function."""

df['Correctness']=""
def is_convertable(v):
    try:
        float(v)
        return 1
    except ValueError:
        return np.nan

df['Correctness']=df.Size.apply(lambda x: is_convertable(x))

"""To clean the data more, we cleaned the rows which has the size "Varies with device.". Then we dropped the na rows."""

df.Size=df.Size.replace('Varies with device',np.nan)
df.dropna(axis=0, subset=['Correctness'],inplace=True)
print("After cleaning the Size column",df.shape)

"""To clean the Installs column, we stripped the indexes which has "+" sign and moreover we converted the indexes which has "," to "". Also to clean the zero rows, we converted "0" to NaN value."""

df.Installs=df.Installs.apply(lambda x: x.strip('+'))
df.Installs=df.Installs.apply(lambda x: x.replace(',',''))
df.Installs=df.Installs.replace('0',np.nan)
df.dropna(axis=0, subset=['Installs'],inplace=True)
print("After cleaning the Installs column",df.shape)

"""To make the Reviews and Rating columns more abstract, we determined the non numeric data and deleted them."""

#df[~df.Reviews.str.isnumeric()] 
df.dropna(axis=0, subset=['Rating'],inplace=True)
print("After cleaning the Rating column",df.shape)

"""After that, for Prices column we stripped the indexes which has "$" sign."""

df.Price=df.Price.apply(lambda x: x.strip('$'))

"""We counted the values of Content_Rating column and since we won't need the Genres column, we deleted it."""

df.Content_Rating.value_counts()
df.drop('Genres',axis=1,inplace=True)

"""For making the Last_Updated column more clear, we converted types of all indexes to datetime. We subtracted dates from today and we figured out when the apps last updated."""

temp=pd.to_datetime(df.Last_Updated)
df['Last_Updated']=temp
df['Last_Updated_Days'] = temp.apply(lambda x:date.today()-datetime.date(x))

"""Finally, we deleted the columns "Correctness", "Current_Ver", "Android_Ver" to predict the ratings of app more clearly."""

df.drop('Correctness',axis=1,inplace=True)
df.drop('Current_Ver',axis=1,inplace=True)
df.drop('Android_Ver',axis=1,inplace=True)
df.sort_values("Category",inplace = True)
df.head()

print(df.dtypes)

"""From here, you can see that we applied data cleaning to our dataframe and made it more clear.

For using preprocessing algorithms, we encoded our data into numerical values.
"""

df["Reviews"] = pd.to_numeric(df["Reviews"])
df["Installs"] = pd.to_numeric(df["Installs"])
df["Price"] = pd.to_numeric(df["Price"])

"""For using machine learning algorithms we need to convert the non-numeric values to dummy columns. 

"""

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

df2=pd.get_dummies(df,columns=['Category'], drop_first=True)
df3=pd.get_dummies(df2,columns=['Content_Rating'], drop_first=True)

df3.head()
df3.columns
#one hot encoding

"""To visualize the data more, we used matplotlib.pyplot"""

plt.figure(figsize=(15,10))
df.Category.value_counts().plot(kind="bar", rot=0, title="Pclass Vs Count", color='c', );
plt.xticks(rotation='vertical');
plt.title("Category Name")
plt.ylabel("Count")
plt.plot();

df['Type Num']=label_encoder.fit_transform(df['Type'])
dict_type ={}

value=0
for i in df['Type'].unique():
  dict_type[i]=value
  value+=1

"""Below this coding cell, our group tried to apply the decision tree regressor with install and review data from googleplaystore.csv. We found out from these method is that actual rating and predicted rating has approximately 0.4601 error. This is not the best method we've used. """

X_DT = df3.drop(['Rating','App','Type','Last_Updated','Last_Updated_Days'], axis=1) # these are features
y_DT = df3['Rating']  # this is the target (what we want to predict)

from sklearn.model_selection import train_test_split

X_train_DT, X_test_DT, y_train_DT, y_test_DT = train_test_split(X_DT, y_DT, random_state=42, test_size=0.25)

from sklearn import tree

model_DT = tree.DecisionTreeRegressor() #Create decision tree classifier object
model_DT.fit(X_train_DT, y_train_DT) #train the classifier using the training data
y_predict_DT = model_DT.predict(X_test_DT)

df_DT=pd.DataFrame({'Actual':y_test_DT, 'Predicted':y_predict_DT})
print(df_DT)

from sklearn import metrics
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_DT, y_predict_DT))
print('Mean Squared Error:', metrics.mean_squared_error(y_test_DT, y_predict_DT))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test_DT, y_predict_DT)))

"""We have found importances of futures below cell."""

feature_list=features
# Convert to numpy array
features = np.array(features)

# Get numerical feature importances
importances = list(model_DT.feature_importances_)
# List of tuples with variable and importance
feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]
# Sort the feature importances by most important first
feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)
# Print out the feature and importances 
[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];

"""We've plot the importances."""

# Set the style
plt.figure(figsize = (15,15))
plt.style.use('fivethirtyeight')
# list of x locations for plotting
x_values = list(range(len(importances)))
# Make a bar chart
plt.bar(x_values, importances, orientation = 'vertical')
# Tick labels for x axis
plt.xticks(x_values, feature_list, rotation='vertical')
# Axis labels and title
plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');

X_DT2 = df3.drop(['Rating','App','Type','Last_Updated','Last_Updated_Days','Installs','Reviews'], axis=1) # these are features
y_DT2 = df3['Rating']  # this is the target (what we want to predict)

X_train_DT2, X_test_DT2, y_train_DT2, y_test_DT2 = train_test_split(X_DT2, y_DT2, random_state=0, test_size=0.25)

model_DT2 = tree.DecisionTreeRegressor() #Create decision tree classifier object
model_DT2.fit(X_train_DT2, y_train_DT2) #train the classifier using the training data
y_predict_DT2 = model_DT2.predict(X_test_DT2)

df_DT2=pd.DataFrame({'Actual':y_test_DT2, 'Predicted':y_predict_DT2})
print(df_DT)

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_DT2, y_predict_DT2))
print('Mean Squared Error:', metrics.mean_squared_error(y_test_DT2, y_predict_DT2))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test_DT2, y_predict_DT2)))

"""Below this coding cell, it can be seen that our group applied Linear Regression model for our dataframe. We wanted to make analysis about existence of correlation between variables."""

from sklearn.linear_model import LinearRegression

feat=['Reviews','Size','Installs','Price','Type Num','Category_AUTO_AND_VEHICLES', 'Category_BEAUTY',
       'Category_BOOKS_AND_REFERENCE', 'Category_BUSINESS', 'Category_COMICS',
       'Category_COMMUNICATION', 'Category_DATING', 'Category_EDUCATION',
       'Category_ENTERTAINMENT', 'Category_EVENTS', 'Category_FAMILY',
       'Category_FINANCE', 'Category_FOOD_AND_DRINK', 'Category_GAME',
       'Category_HEALTH_AND_FITNESS', 'Category_HOUSE_AND_HOME',
       'Category_LIBRARIES_AND_DEMO', 'Category_LIFESTYLE',
       'Category_MAPS_AND_NAVIGATION', 'Category_MEDICAL',
       'Category_NEWS_AND_MAGAZINES', 'Category_PARENTING',
       'Category_PERSONALIZATION', 'Category_PHOTOGRAPHY',
       'Category_PRODUCTIVITY', 'Category_SHOPPING', 'Category_SOCIAL',
       'Category_SPORTS', 'Category_TOOLS', 'Category_TRAVEL_AND_LOCAL',
       'Category_VIDEO_PLAYERS', 'Category_WEATHER', 'Content_Rating_Everyone',
       'Content_Rating_Everyone 10+', 'Content_Rating_Mature 17+',
       'Content_Rating_Teen', 'Content_Rating_Unrated']
X_LR= df3[feat].values
y_LR = df3['Rating'].values  # this is the target (what we want to predict)

X_train_LR, X_test_LR, y_train_LR, y_test_LR = train_test_split(X_LR, y_LR, test_size=0.25, random_state=0)

model_LR = LinearRegression()  
model_LR.fit(X_train_LR, y_train_LR)

coeff_df = pd.DataFrame(model_LR.coef_, feat, columns=['Coefficient'])  
print(coeff_df)
print()

from sklearn.metrics import mean_squared_error, mean_absolute_error

y_pred_LR = model_LR.predict(X_test_LR)

mse_LR = mean_squared_error(y_test_LR, y_pred_LR)
mae_LR = mean_absolute_error(y_test_LR, y_pred_LR)
rmse_LR = np.sqrt(mse_LR)

print("Mean Absolute Error: {}".format(mae_LR))
print("Mean Squared Error: {}".format(mse_LR))
print("Root Mean Squared Error: {}".format(rmse_LR))

feat=['Size','Price','Type Num','Category_AUTO_AND_VEHICLES', 'Category_BEAUTY',
       'Category_BOOKS_AND_REFERENCE', 'Category_BUSINESS', 'Category_COMICS',
       'Category_COMMUNICATION', 'Category_DATING', 'Category_EDUCATION',
       'Category_ENTERTAINMENT', 'Category_EVENTS', 'Category_FAMILY',
       'Category_FINANCE', 'Category_FOOD_AND_DRINK', 'Category_GAME',
       'Category_HEALTH_AND_FITNESS', 'Category_HOUSE_AND_HOME',
       'Category_LIBRARIES_AND_DEMO', 'Category_LIFESTYLE',
       'Category_MAPS_AND_NAVIGATION', 'Category_MEDICAL',
       'Category_NEWS_AND_MAGAZINES', 'Category_PARENTING',
       'Category_PERSONALIZATION', 'Category_PHOTOGRAPHY',
       'Category_PRODUCTIVITY', 'Category_SHOPPING', 'Category_SOCIAL',
       'Category_SPORTS', 'Category_TOOLS', 'Category_TRAVEL_AND_LOCAL',
       'Category_VIDEO_PLAYERS', 'Category_WEATHER', 'Content_Rating_Everyone',
       'Content_Rating_Everyone 10+', 'Content_Rating_Mature 17+',
       'Content_Rating_Teen', 'Content_Rating_Unrated']

X_LR2= df3[feat].values
y_LR2 = df3['Rating'].values  # this is the target (what we want to predict)

X_train_LR2, X_test_LR2, y_train_LR2, y_test_LR2 = train_test_split(X_LR2, y_LR2, test_size=0.25, random_state=0)

model_LR2 = LinearRegression()  
model_LR2.fit(X_train_LR2, y_train_LR2)

coeff_df2 = pd.DataFrame(model_LR2.coef_, feat, columns=['Coefficient'])  
print(coeff_df2)
print()

y_pred_LR2 = model_LR2.predict(X_test_LR2)

mse_LR2 = mean_squared_error(y_test_LR2, y_pred_LR2)
mae_LR2 = mean_absolute_error(y_test_LR2, y_pred_LR2)
rmse_LR2 = np.sqrt(rmse_LR2)

print("Mean Absolute Error: {}".format(mae_LR2))
print("Mean Squared Error: {}".format(mse_LR2))
print("Root Mean Squared Error: {}".format(rmse_LR2))

"""Below this coding cell..."""

from sklearn.neighbors import KNeighborsRegressor

# Split data into training and testing sets
features = ['Reviews','Size','Installs','Price','Type Num','Category_AUTO_AND_VEHICLES', 'Category_BEAUTY',
       'Category_BOOKS_AND_REFERENCE', 'Category_BUSINESS', 'Category_COMICS',
       'Category_COMMUNICATION', 'Category_DATING', 'Category_EDUCATION',
       'Category_ENTERTAINMENT', 'Category_EVENTS', 'Category_FAMILY',
       'Category_FINANCE', 'Category_FOOD_AND_DRINK', 'Category_GAME',
       'Category_HEALTH_AND_FITNESS', 'Category_HOUSE_AND_HOME',
       'Category_LIBRARIES_AND_DEMO', 'Category_LIFESTYLE',
       'Category_MAPS_AND_NAVIGATION', 'Category_MEDICAL',
       'Category_NEWS_AND_MAGAZINES', 'Category_PARENTING',
       'Category_PERSONALIZATION', 'Category_PHOTOGRAPHY',
       'Category_PRODUCTIVITY', 'Category_SHOPPING', 'Category_SOCIAL',
       'Category_SPORTS', 'Category_TOOLS', 'Category_TRAVEL_AND_LOCAL',
       'Category_VIDEO_PLAYERS', 'Category_WEATHER', 'Content_Rating_Everyone',
       'Content_Rating_Everyone 10+', 'Content_Rating_Mature 17+',
       'Content_Rating_Teen', 'Content_Rating_Unrated']
X_KNN = df3[features]
y_KNN = df3['Rating']

X_train_KNN, X_test_KNN, y_train_KNN, y_test_KNN = train_test_split(X_KNN, y_KNN, test_size = 0.25, random_state = 10)
# Look at the 500 closest neighbors
model_KNN = KNeighborsRegressor(n_neighbors=500)
# Find the mean accuracy of knn regression using X_test and y_test
model_KNN.fit(X_train_KNN, y_train_KNN)
model_pred_KNN=model_KNN.predict(X_test_KNN)

mse_KNN = mean_squared_error(y_test_KNN, model_pred_KNN)
mae_KNN = mean_absolute_error(y_test_KNN, model_pred_KNN)
rmse_KNN = np.sqrt(mse)

print("Mean Absolute Error: {}".format(mae_KNN))
print("Mean Squared Error: {}".format(mse_KNN))
print("Root Mean Squared Error: {}".format(rmse_KNN))

import seaborn as sns
plt.figure(figsize = (10,10))

sns.heatmap(df.corr(method = 'spearman'), annot = True, fmt = '.2f', square = True, center = 0, cmap = 'coolwarm')

plt.yticks(rotation=0)

"""Above this coding cell, it can be seen correlation between categories.

Also, from below coding cell we tried feature selection and random forest regression.
"""

# Features selection
features = ['Reviews','Size','Installs','Price','Type Num','Category_AUTO_AND_VEHICLES', 'Category_BEAUTY',
       'Category_BOOKS_AND_REFERENCE', 'Category_BUSINESS', 'Category_COMICS',
       'Category_COMMUNICATION', 'Category_DATING', 'Category_EDUCATION',
       'Category_ENTERTAINMENT', 'Category_EVENTS', 'Category_FAMILY',
       'Category_FINANCE', 'Category_FOOD_AND_DRINK', 'Category_GAME',
       'Category_HEALTH_AND_FITNESS', 'Category_HOUSE_AND_HOME',
       'Category_LIBRARIES_AND_DEMO', 'Category_LIFESTYLE',
       'Category_MAPS_AND_NAVIGATION', 'Category_MEDICAL',
       'Category_NEWS_AND_MAGAZINES', 'Category_PARENTING',
       'Category_PERSONALIZATION', 'Category_PHOTOGRAPHY',
       'Category_PRODUCTIVITY', 'Category_SHOPPING', 'Category_SOCIAL',
       'Category_SPORTS', 'Category_TOOLS', 'Category_TRAVEL_AND_LOCAL',
       'Category_VIDEO_PLAYERS', 'Category_WEATHER', 'Content_Rating_Everyone',
       'Content_Rating_Everyone 10+', 'Content_Rating_Mature 17+',
       'Content_Rating_Teen', 'Content_Rating_Unrated']
X_RF = df3[features]
# Label selection
y_RF = df3.Rating
# For testing purpose
train_X_RF, test_X_RF, train_y_RF, test_y_RF = train_test_split(X_RF, y_RF, test_size = 0.25,random_state=0)

#Random Forest Regression
RF_model = RandomForestRegressor(n_estimators=100, max_features=3, min_samples_leaf=10)
RF_model.fit(X_RF,y_RF)
#For testing purposes
RF_model.fit(train_X_RF, train_y_RF)
RF_pred= RF_model.predict(test_X_RF)

print('Mean Absolute Error:', metrics.mean_absolute_error(test_y_RF, RF_pred))
print('Mean Squared Error:', metrics.mean_squared_error(test_y_RF, RF_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y_RF, RF_pred)))

# Calculate the absolute errors
#errors_RF = abs(RF_pred - test_y)

# Calculate mean absolute percentage error (MAPE)
#mape = 100 * (errors_RF / test_y)

# Print out the mean absolute error (mae)
#print('Mean Absolute Error:', round(np.mean(errors_RF), 2))

#Print out the result Rating
#print('Rating is :', round(np.median(TotalSum), 2))

features2 = ['Size','Price','Type Num','Category_AUTO_AND_VEHICLES', 'Category_BEAUTY',
       'Category_BOOKS_AND_REFERENCE', 'Category_BUSINESS', 'Category_COMICS',
       'Category_COMMUNICATION', 'Category_DATING', 'Category_EDUCATION',
       'Category_ENTERTAINMENT', 'Category_EVENTS', 'Category_FAMILY',
       'Category_FINANCE', 'Category_FOOD_AND_DRINK', 'Category_GAME',
       'Category_HEALTH_AND_FITNESS', 'Category_HOUSE_AND_HOME',
       'Category_LIBRARIES_AND_DEMO', 'Category_LIFESTYLE',
       'Category_MAPS_AND_NAVIGATION', 'Category_MEDICAL',
       'Category_NEWS_AND_MAGAZINES', 'Category_PARENTING',
       'Category_PERSONALIZATION', 'Category_PHOTOGRAPHY',
       'Category_PRODUCTIVITY', 'Category_SHOPPING', 'Category_SOCIAL',
       'Category_SPORTS', 'Category_TOOLS', 'Category_TRAVEL_AND_LOCAL',
       'Category_VIDEO_PLAYERS', 'Category_WEATHER', 'Content_Rating_Everyone',
       'Content_Rating_Everyone 10+', 'Content_Rating_Mature 17+',
       'Content_Rating_Teen', 'Content_Rating_Unrated']
X_RF2 = df3[features2]
# Label selection
y_RF2 = df3.Rating
# For testing purpose
train_X_RF2, test_X_RF2, train_y_RF2, test_y_RF2 = train_test_split(X_RF2, y_RF2, test_size = 0.25,random_state=0)

#Random Forest Regression
RF_model2 = RandomForestRegressor(n_estimators=100, max_features=3, min_samples_leaf=10)
RF_model2.fit(X_RF2,y_RF2)
#For testing purposes
RF_model2.fit(train_X_RF2, train_y_RF2)
RF_pred2= RF_model2.predict(test_X_RF2)

print('Mean Absolute Error:', metrics.mean_absolute_error(test_y_RF2, RF_pred2))
print('Mean Squared Error:', metrics.mean_squared_error(test_y_RF2, RF_pred2))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y_RF2, RF_pred2)))

"""Below this coding cell, firstly, we converted our feature_list to numpy array. After that, we get numerical feature importances and divided it with list of tuples with variable and importance. Then we sorted the feature importances by most important first. """

feature_list=features
# Convert to numpy array
features = np.array(features)

# Get numerical feature importances
importances = list(RF_model.feature_importances_)
# List of tuples with variable and importance
feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]
# Sort the feature importances by most important first
feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)
# Print out the feature and importances 
[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];

"""Then we plotted the graph."""

# Set the style
plt.figure(figsize = (15,15))
plt.style.use('fivethirtyeight')
# list of x locations for plotting
x_values = list(range(len(importances)))
# Make a bar chart
plt.bar(x_values, importances, orientation = 'vertical')
# Tick labels for x axis
plt.xticks(x_values, feature_list, rotation='vertical')
# Axis labels and title
plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');

"""Dataset contains immense possibilities to improve business values and have a positive impact. It is not limited to the problem taken into consideration for this project. Many other interesting possibilities can be explored using this dataset.

Future work can be include: 
Prediction of the number of reviews and installs by using the regression model. Identifying the categories and stats of the most installed apps. Exploring the correlation between the size of the app, the version of Android, etc on the number of installs. The ways in which questions can be asked varies, so does the way of tackling a problem. Only the one that has been minutely observed and tested will provide results worth trusting.
"""